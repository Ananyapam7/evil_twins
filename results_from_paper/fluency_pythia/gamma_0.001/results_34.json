[
    {
        "epoch": 1,
        "loss": 4.149325847625732,
        "best_loss": 4.149325847625732,
        "best_kl": 44.237186431884766,
        "best_std": 1.4261590957641601,
        "cur_kl": 44.237186431884766,
        "cur_std": 1.4261590957641601,
        "prompt": " itchallengzm largest;{\\ Hoff was tractsmail polym",
        "nll_prompt": -129.638671875
    },
    {
        "epoch": 2,
        "loss": 4.252641677856445,
        "best_loss": 4.149325847625732,
        "best_kl": 40.97281265258789,
        "best_std": 1.4060073852539063,
        "cur_kl": 40.97281265258789,
        "cur_std": 1.4060073852539063,
        "prompt": " itchallengzm largest;{\\ Hoff was tractsmailopoulos",
        "nll_prompt": -129.5166015625
    },
    {
        "epoch": 3,
        "loss": 3.976860284805298,
        "best_loss": 3.976860284805298,
        "best_kl": 39.77093505859375,
        "best_std": 1.4215265274047852,
        "cur_kl": 39.77093505859375,
        "cur_std": 1.4215265274047852,
        "prompt": "Deltachallengzm largest;{\\ Hoff was tractsmailopoulos",
        "nll_prompt": -133.4228515625
    },
    {
        "epoch": 4,
        "loss": 3.988037109375,
        "best_loss": 3.976860284805298,
        "best_kl": 38.197811126708984,
        "best_std": 1.4030721664428711,
        "cur_kl": 38.197811126708984,
        "cur_std": 1.4030721664428711,
        "prompt": "Deltachallengzm largest;{\\ Hoff49 tractsmailopoulos",
        "nll_prompt": -132.568359375
    },
    {
        "epoch": 5,
        "loss": 4.016352653503418,
        "best_loss": 3.976860284805298,
        "best_kl": 37.53531265258789,
        "best_std": 1.4235735893249513,
        "cur_kl": 37.53531265258789,
        "cur_std": 1.4235735893249513,
        "prompt": "Deltachallengzm largest;{\\ Hoff49livmailopoulos",
        "nll_prompt": -132.4462890625
    },
    {
        "epoch": 6,
        "loss": 4.012743949890137,
        "best_loss": 3.976860284805298,
        "best_kl": 35.86843490600586,
        "best_std": 1.4035103797912598,
        "cur_kl": 35.86843490600586,
        "cur_std": 1.4035103797912598,
        "prompt": "Deltachallengzm largest;{\\ opportunities49livmailopoulos",
        "nll_prompt": -133.056640625
    },
    {
        "epoch": 7,
        "loss": 4.070268630981445,
        "best_loss": 3.976860284805298,
        "best_kl": 35.590938568115234,
        "best_std": 1.3505075454711915,
        "cur_kl": 35.590938568115234,
        "cur_std": 1.3505075454711915,
        "prompt": "Deltachallengzm largest;{\\ opportunities49liv poetryopoulos",
        "nll_prompt": -134.6435546875
    },
    {
        "epoch": 8,
        "loss": 3.769106388092041,
        "best_loss": 3.769106388092041,
        "best_kl": 34.459686279296875,
        "best_std": 1.3537632942199707,
        "cur_kl": 34.459686279296875,
        "cur_std": 1.3537632942199707,
        "prompt": "Deltachallengzm largestject opportunities49liv poetryopoulos",
        "nll_prompt": -130.9814453125
    },
    {
        "epoch": 9,
        "loss": 3.8395214080810547,
        "best_loss": 3.769106388092041,
        "best_kl": 34.05531311035156,
        "best_std": 1.3500569343566895,
        "cur_kl": 34.05531311035156,
        "cur_std": 1.3500569343566895,
        "prompt": "Deltachallengzm largestject SO49liv poetryopoulos",
        "nll_prompt": -126.708984375
    },
    {
        "epoch": 10,
        "loss": 4.050312519073486,
        "best_loss": 3.769106388092041,
        "best_kl": 32.79656219482422,
        "best_std": 1.3518186569213868,
        "cur_kl": 32.79656219482422,
        "cur_std": 1.3518186569213868,
        "prompt": "Deltachallengzm whenject SO49liv poetryopoulos",
        "nll_prompt": -128.90625
    },
    {
        "epoch": 11,
        "loss": 3.766550302505493,
        "best_loss": 3.766550302505493,
        "best_kl": 32.79656219482422,
        "best_std": 1.3518186569213868,
        "cur_kl": 32.90156173706055,
        "cur_std": 1.3712084770202637,
        "prompt": "Deltachallengzm whenject SO49liv poetry blog",
        "nll_prompt": -120.30029296875
    },
    {
        "epoch": 12,
        "loss": 3.9147558212280273,
        "best_loss": 3.766550302505493,
        "best_kl": 32.00531005859375,
        "best_std": 1.3542409896850587,
        "cur_kl": 32.00531005859375,
        "cur_std": 1.3542409896850587,
        "prompt": "Deltachallengzm whenject SO49liv anxiety blog",
        "nll_prompt": -120.849609375
    },
    {
        "epoch": 13,
        "loss": 3.875256299972534,
        "best_loss": 3.766550302505493,
        "best_kl": 31.978437423706055,
        "best_std": 1.3626197814941405,
        "cur_kl": 31.978437423706055,
        "cur_std": 1.3626197814941405,
        "prompt": "Deltachallengzm whenject().49liv anxiety blog",
        "nll_prompt": -118.22509765625
    },
    {
        "epoch": 14,
        "loss": 3.871699094772339,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 31.72718620300293,
        "cur_std": 1.3685632705688477,
        "prompt": "Deltachallengzm whenject(). recreationliv anxiety blog",
        "nll_prompt": -120.60546875
    },
    {
        "epoch": 15,
        "loss": 3.8700268268585205,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 32.122188568115234,
        "cur_std": 1.3664466857910156,
        "prompt": "Deltachallengzm whenared(). recreationliv anxiety blog",
        "nll_prompt": -121.27685546875
    },
    {
        "epoch": 16,
        "loss": 3.7928466796875,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 33.00406265258789,
        "cur_std": 1.3613717079162597,
        "prompt": "Deltachallengzm importantared(). recreationliv anxiety blog",
        "nll_prompt": -120.9716796875
    },
    {
        "epoch": 17,
        "loss": 3.8142943382263184,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 36.70781326293945,
        "cur_std": 1.3160931587219238,
        "prompt": "Deltachallengzm importantared(). recreationliv anxiety that",
        "nll_prompt": -116.63818359375
    },
    {
        "epoch": 18,
        "loss": 4.162534236907959,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 35.78531265258789,
        "cur_std": 1.3377601623535156,
        "prompt": "Deltachallengzm importantared(). recreationlivquez that",
        "nll_prompt": -117.0654296875
    },
    {
        "epoch": 19,
        "loss": 4.046418190002441,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 33.25531005859375,
        "cur_std": 1.3117897033691406,
        "prompt": "Deltachallengzm important Some(). recreationlivquez that",
        "nll_prompt": -121.88720703125
    },
    {
        "epoch": 20,
        "loss": 4.054509162902832,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 33.81968688964844,
        "cur_std": 1.3264565467834473,
        "prompt": "DeltachallengAn important Some(). recreationlivquez that",
        "nll_prompt": -114.19677734375
    },
    {
        "epoch": 21,
        "loss": 3.9233129024505615,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 35.72281265258789,
        "cur_std": 1.3221111297607422,
        "prompt": "DeltachallengAn important Someprehens recreationlivquez that",
        "nll_prompt": -122.37548828125
    },
    {
        "epoch": 22,
        "loss": 3.979804515838623,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 37.62031173706055,
        "cur_std": 1.335734748840332,
        "prompt": "Delta theAn important Someprehens recreationlivquez that",
        "nll_prompt": -112.3046875
    },
    {
        "epoch": 23,
        "loss": 4.081096172332764,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 34.46531295776367,
        "cur_std": 1.3113481521606445,
        "prompt": "Delta theAn important Someprehens FRlivquez that",
        "nll_prompt": -111.87744140625
    },
    {
        "epoch": 24,
        "loss": 3.8402295112609863,
        "best_loss": 3.766550302505493,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 33.549686431884766,
        "cur_std": 1.2992218017578125,
        "prompt": "Delta theAnτικ Someprehens FRlivquez that",
        "nll_prompt": -110.2294921875
    },
    {
        "epoch": 25,
        "loss": 3.666066884994507,
        "best_loss": 3.666066884994507,
        "best_kl": 31.72718620300293,
        "best_std": 1.3685632705688477,
        "cur_kl": 31.983749389648438,
        "cur_std": 1.2300620079040527,
        "prompt": "Delta theAnτικ Closeprehens FRlivquez that",
        "nll_prompt": -124.81689453125
    },
    {
        "epoch": 26,
        "loss": 3.828068733215332,
        "best_loss": 3.666066884994507,
        "best_kl": 30.74656105041504,
        "best_std": 1.2475258827209472,
        "cur_kl": 30.74656105041504,
        "cur_std": 1.2475258827209472,
        "prompt": "Delta the Variablesτικ Closeprehens FRlivquez that",
        "nll_prompt": -122.13134765625
    },
    {
        "epoch": 27,
        "loss": 3.686164379119873,
        "best_loss": 3.666066884994507,
        "best_kl": 30.74656105041504,
        "best_std": 1.2475258827209472,
        "cur_kl": 31.579999923706055,
        "cur_std": 1.222799301147461,
        "prompt": "Delta the Makeτικ Closeprehens FRlivquez that",
        "nll_prompt": -123.35205078125
    },
    {
        "epoch": 28,
        "loss": 4.053335189819336,
        "best_loss": 3.666066884994507,
        "best_kl": 30.74656105041504,
        "best_std": 1.2475258827209472,
        "cur_kl": 32.075313568115234,
        "cur_std": 1.2231574058532715,
        "prompt": "Delta the Makeτικ CloseprehensANDlivquez that",
        "nll_prompt": -121.4599609375
    },
    {
        "epoch": 29,
        "loss": 3.914785146713257,
        "best_loss": 3.666066884994507,
        "best_kl": 30.74656105041504,
        "best_std": 1.2475258827209472,
        "cur_kl": 33.25156021118164,
        "cur_std": 1.2812311172485351,
        "prompt": "Delta the Makeτικ tilprehensANDlivquez that",
        "nll_prompt": -115.72265625
    },
    {
        "epoch": 30,
        "loss": 3.9980688095092773,
        "best_loss": 3.666066884994507,
        "best_kl": 30.74656105041504,
        "best_std": 1.2475258827209472,
        "cur_kl": 31.732187271118164,
        "cur_std": 1.2688179016113281,
        "prompt": "Delta the Makeτικ tilprehensANDliv answering that",
        "nll_prompt": -114.31884765625
    },
    {
        "epoch": 31,
        "loss": 3.7752881050109863,
        "best_loss": 3.666066884994507,
        "best_kl": 30.74656105041504,
        "best_std": 1.2475258827209472,
        "cur_kl": 30.92656135559082,
        "cur_std": 1.251688575744629,
        "prompt": "Delta the MakeτικёprehensANDliv answering that",
        "nll_prompt": -111.6943359375
    },
    {
        "epoch": 32,
        "loss": 3.586738109588623,
        "best_loss": 3.586738109588623,
        "best_kl": 29.81718635559082,
        "best_std": 1.2292057037353517,
        "cur_kl": 29.81718635559082,
        "cur_std": 1.2292057037353517,
        "prompt": "Delta the MakeτικёprehensAND Connect answering that",
        "nll_prompt": -109.86328125
    },
    {
        "epoch": 33,
        "loss": 3.8873069286346436,
        "best_loss": 3.586738109588623,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 29.702186584472656,
        "cur_std": 1.2153802871704102,
        "prompt": "Delta theourageτικёprehensAND Connect answering that",
        "nll_prompt": -110.90087890625
    },
    {
        "epoch": 34,
        "loss": 3.5337767601013184,
        "best_loss": 3.5337767601013184,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 30.507186889648438,
        "cur_std": 1.2259347915649415,
        "prompt": "Delta theourageτικigrationprehensAND Connect answering that",
        "nll_prompt": -121.27685546875
    },
    {
        "epoch": 35,
        "loss": 3.4674534797668457,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 30.763750076293945,
        "cur_std": 1.2206350326538087,
        "prompt": "incess theourageτικigrationprehensAND Connect answering that",
        "nll_prompt": -120.42236328125
    },
    {
        "epoch": 36,
        "loss": 3.8745603561401367,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 30.71468734741211,
        "cur_std": 1.2492154121398926,
        "prompt": "incess the versaτικigrationprehensAND Connect answering that",
        "nll_prompt": -115.966796875
    },
    {
        "epoch": 37,
        "loss": 3.5837059020996094,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 31.014686584472656,
        "cur_std": 1.252807903289795,
        "prompt": "incess Rh versaτικigrationprehensAND Connect answering that",
        "nll_prompt": -122.9248046875
    },
    {
        "epoch": 38,
        "loss": 3.6129589080810547,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 31.45781135559082,
        "cur_std": 1.2609578132629395,
        "prompt": "incess'(\\ versaτικigrationprehensAND Connect answering that",
        "nll_prompt": -126.708984375
    },
    {
        "epoch": 39,
        "loss": 3.841987133026123,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 31.44218635559082,
        "cur_std": 1.2450980186462401,
        "prompt": "Base'(\\ versaτικigrationprehensAND Connect answering that",
        "nll_prompt": -134.6435546875
    },
    {
        "epoch": 40,
        "loss": 3.936840772628784,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 30.48406219482422,
        "cur_std": 1.1906461715698242,
        "prompt": "Base'(\\ versaτικigrationprehensAND Keep answering that",
        "nll_prompt": -129.0283203125
    },
    {
        "epoch": 41,
        "loss": 3.881425619125366,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 30.759687423706055,
        "cur_std": 1.2212437629699706,
        "prompt": "Base'(\\ versaτικigrationprehens much Keep answering that",
        "nll_prompt": -121.58203125
    },
    {
        "epoch": 42,
        "loss": 3.840895891189575,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 31.248435974121094,
        "cur_std": 1.2436766624450684,
        "prompt": " dominate'(\\ versaτικigrationprehens much Keep answering that",
        "nll_prompt": -117.61474609375
    },
    {
        "epoch": 43,
        "loss": 3.9458837509155273,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 30.092811584472656,
        "cur_std": 1.2064760208129883,
        "prompt": " dominate'(\\ versaτικigrationprehens answer Keep answering that",
        "nll_prompt": -112.9150390625
    },
    {
        "epoch": 44,
        "loss": 3.883000373840332,
        "best_loss": 3.4674534797668457,
        "best_kl": 29.702186584472656,
        "best_std": 1.2153802871704102,
        "cur_kl": 29.8721866607666,
        "cur_std": 1.1726828575134278,
        "prompt": "btn'(\\ versaτικigrationprehens answer Keep answering that",
        "nll_prompt": -114.56298828125
    },
    {
        "epoch": 45,
        "loss": 3.7442870140075684,
        "best_loss": 3.4674534797668457,
        "best_kl": 28.62093734741211,
        "best_std": 1.1727865219116211,
        "cur_kl": 28.62093734741211,
        "cur_std": 1.1727865219116211,
        "prompt": "uk'(\\ versaτικigrationprehens answer Keep answering that",
        "nll_prompt": -109.130859375
    },
    {
        "epoch": 46,
        "loss": 3.858042001724243,
        "best_loss": 3.4674534797668457,
        "best_kl": 28.62093734741211,
        "best_std": 1.1727865219116211,
        "cur_kl": 30.290937423706055,
        "cur_std": 1.222879981994629,
        "prompt": "uk'(\\ versaτικigrationprehens answer discouraged answering that",
        "nll_prompt": -110.2294921875
    },
    {
        "epoch": 47,
        "loss": 3.948195695877075,
        "best_loss": 3.4674534797668457,
        "best_kl": 28.62093734741211,
        "best_std": 1.1727865219116211,
        "cur_kl": 31.054061889648438,
        "cur_std": 1.2832600593566894,
        "prompt": "uk'(\\ versaτικigrationprehens answer discouraged answeringav",
        "nll_prompt": -119.44580078125
    },
    {
        "epoch": 48,
        "loss": 3.671943187713623,
        "best_loss": 3.4674534797668457,
        "best_kl": 28.62093734741211,
        "best_std": 1.1727865219116211,
        "cur_kl": 31.28968620300293,
        "cur_std": 1.2859255790710449,
        "prompt": "uk'(\\ versaτικigrationprehens answer Names answeringav",
        "nll_prompt": -120.849609375
    },
    {
        "epoch": 49,
        "loss": 3.858759641647339,
        "best_loss": 3.4674534797668457,
        "best_kl": 28.62093734741211,
        "best_std": 1.1727865219116211,
        "cur_kl": 31.767812728881836,
        "cur_std": 1.2997316360473632,
        "prompt": "uk vra versaτικigrationprehens answer Names answeringav",
        "nll_prompt": -123.291015625
    },
    {
        "epoch": 50,
        "loss": 3.844973087310791,
        "best_loss": 3.4674534797668457,
        "best_kl": 28.62093734741211,
        "best_std": 1.1727865219116211,
        "cur_kl": 31.100936889648438,
        "cur_std": 1.2905016899108888,
        "prompt": "uk vra versaτικigrationprehens answer Namesgrowav",
        "nll_prompt": -124.81689453125
    }
]
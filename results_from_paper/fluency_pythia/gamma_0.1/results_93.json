[
    {
        "epoch": 1,
        "loss": 16.743436813354492,
        "best_loss": 16.743436813354492,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 41.12249755859375,
        "cur_std": 1.3976405143737793,
        "prompt": " pursued phys cannabisaffinityle judiciary Strateg RFF HV",
        "nll_prompt": -118.59375
    },
    {
        "epoch": 2,
        "loss": 15.834687232971191,
        "best_loss": 15.834687232971191,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 41.60562515258789,
        "cur_std": 1.377739715576172,
        "prompt": " pursued phys cannabisaffinityle judiciary need RFF HV",
        "nll_prompt": -111.09375
    },
    {
        "epoch": 3,
        "loss": 15.395936965942383,
        "best_loss": 15.395936965942383,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 41.61750030517578,
        "cur_std": 1.3914682388305664,
        "prompt": "French phys cannabisaffinityle judiciary need RFF HV",
        "nll_prompt": -107.890625
    },
    {
        "epoch": 4,
        "loss": 14.454062461853027,
        "best_loss": 14.454062461853027,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 41.87999725341797,
        "cur_std": 1.3978272438049317,
        "prompt": "French phys cannabisackle judiciary need RFF HV",
        "nll_prompt": -100.0
    },
    {
        "epoch": 5,
        "loss": 14.501249313354492,
        "best_loss": 14.454062461853027,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 43.62687301635742,
        "cur_std": 1.4056025505065919,
        "prompt": "French phys cannabisackle judiciary need RFF watch",
        "nll_prompt": -96.71875
    },
    {
        "epoch": 6,
        "loss": 13.715937614440918,
        "best_loss": 13.715937614440918,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 43.83374786376953,
        "cur_std": 1.3854413986206056,
        "prompt": "French phys cannabisackle judiciary need RFF\n",
        "nll_prompt": -92.65625
    },
    {
        "epoch": 7,
        "loss": 13.488750457763672,
        "best_loss": 13.488750457763672,
        "best_kl": 41.12249755859375,
        "best_std": 1.3976405143737793,
        "cur_kl": 41.25374984741211,
        "cur_std": 1.3459626197814942,
        "prompt": "French phys cannabisackle x need RFF\n",
        "nll_prompt": -88.125
    },
    {
        "epoch": 8,
        "loss": 12.870311737060547,
        "best_loss": 12.870311737060547,
        "best_kl": 39.73249816894531,
        "best_std": 1.2869194984436034,
        "cur_kl": 39.73249816894531,
        "cur_std": 1.2869194984436034,
        "prompt": "French phys Jackle x need RFF\n",
        "nll_prompt": -81.640625
    },
    {
        "epoch": 9,
        "loss": 12.395312309265137,
        "best_loss": 12.395312309265137,
        "best_kl": 38.21562576293945,
        "best_std": 1.2725687980651856,
        "cur_kl": 38.21562576293945,
        "cur_std": 1.2725687980651856,
        "prompt": "French phys Tackle x need RFF\n",
        "nll_prompt": -76.796875
    },
    {
        "epoch": 10,
        "loss": 11.94921875,
        "best_loss": 11.94921875,
        "best_kl": 38.21562576293945,
        "best_std": 1.2725687980651856,
        "cur_kl": 39.12812423706055,
        "cur_std": 1.2848715782165527,
        "prompt": "French university Tackle x need RFF\n",
        "nll_prompt": -71.7578125
    },
    {
        "epoch": 11,
        "loss": 11.540781021118164,
        "best_loss": 11.540781021118164,
        "best_kl": 38.21562576293945,
        "best_std": 1.2725687980651856,
        "cur_kl": 40.885623931884766,
        "cur_std": 1.3019207000732422,
        "prompt": "French university Tackle the need RFF\n",
        "nll_prompt": -65.1171875
    },
    {
        "epoch": 12,
        "loss": 11.437187194824219,
        "best_loss": 11.437187194824219,
        "best_kl": 38.21562576293945,
        "best_std": 1.2725687980651856,
        "cur_kl": 39.48999786376953,
        "cur_std": 1.281447982788086,
        "prompt": "French university Tackle the need RFF created",
        "nll_prompt": -68.046875
    },
    {
        "epoch": 13,
        "loss": 11.424375534057617,
        "best_loss": 11.424375534057617,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 37.65562438964844,
        "cur_std": 1.2915077209472656,
        "prompt": "French 45 Tackle the need RFF created",
        "nll_prompt": -69.0625
    },
    {
        "epoch": 14,
        "loss": 11.21859359741211,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 40.17937469482422,
        "cur_std": 1.29739408493042,
        "prompt": "French interests Tackle the need RFF created",
        "nll_prompt": -66.3671875
    },
    {
        "epoch": 15,
        "loss": 11.564687728881836,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 37.666873931884766,
        "cur_std": 1.2740994453430177,
        "prompt": "}, interests Tackle the need RFF created",
        "nll_prompt": -72.1875
    },
    {
        "epoch": 16,
        "loss": 11.444999694824219,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 41.18000030517578,
        "cur_std": 1.3205368041992187,
        "prompt": "will interests Tackle the need RFF created",
        "nll_prompt": -67.421875
    },
    {
        "epoch": 17,
        "loss": 11.533124923706055,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 40.31624984741211,
        "cur_std": 1.291063117980957,
        "prompt": " Layer interests Tackle the need RFF created",
        "nll_prompt": -70.0
    },
    {
        "epoch": 18,
        "loss": 11.803437232971191,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 39.80937576293945,
        "cur_std": 1.3082887649536132,
        "prompt": " Layerxiv Tackle the need RFF created",
        "nll_prompt": -72.109375
    },
    {
        "epoch": 19,
        "loss": 11.75796890258789,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 37.859375,
        "cur_std": 1.2741141319274902,
        "prompt": " Layer exactly Tackle the need RFF created",
        "nll_prompt": -69.8046875
    },
    {
        "epoch": 20,
        "loss": 11.231874465942383,
        "best_loss": 11.21859359741211,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 39.17499923706055,
        "cur_std": 1.3267629623413086,
        "prompt": " insights exactly Tackle the need RFF created",
        "nll_prompt": -65.234375
    },
    {
        "epoch": 21,
        "loss": 11.002968788146973,
        "best_loss": 11.002968788146973,
        "best_kl": 37.65562438964844,
        "best_std": 1.2915077209472656,
        "cur_kl": 39.87999725341797,
        "cur_std": 1.279653835296631,
        "prompt": " insights exactly Tackle the need RFF to",
        "nll_prompt": -62.4609375
    },
    {
        "epoch": 22,
        "loss": 11.173749923706055,
        "best_loss": 11.002968788146973,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 34.037498474121094,
        "cur_std": 1.3147479057312013,
        "prompt": " insights exactly Tackle the need RFF)",
        "nll_prompt": -66.875
    },
    {
        "epoch": 23,
        "loss": 11.282187461853027,
        "best_loss": 11.002968788146973,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 34.89187240600586,
        "cur_std": 1.2966801643371582,
        "prompt": " insights exactly Tackle the need RCopy)",
        "nll_prompt": -68.125
    },
    {
        "epoch": 24,
        "loss": 11.02359390258789,
        "best_loss": 11.002968788146973,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 35.85312271118164,
        "cur_std": 1.3179622650146485,
        "prompt": " Budget exactly Tackle the need RCopy)",
        "nll_prompt": -64.4921875
    },
    {
        "epoch": 25,
        "loss": 11.05843734741211,
        "best_loss": 11.002968788146973,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 35.354373931884766,
        "cur_std": 1.3370288848876952,
        "prompt": " Budget exactly Tackle the3 RCopy)",
        "nll_prompt": -68.125
    },
    {
        "epoch": 26,
        "loss": 11.118749618530273,
        "best_loss": 11.002968788146973,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 35.53249740600586,
        "cur_std": 1.3305551528930664,
        "prompt": " Budget exactly Tackle the chain RCopy)",
        "nll_prompt": -67.890625
    },
    {
        "epoch": 27,
        "loss": 10.795937538146973,
        "best_loss": 10.795937538146973,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 35.74187469482422,
        "cur_std": 1.348423957824707,
        "prompt": " Budget 0 Tackle the chain RCopy)",
        "nll_prompt": -63.515625
    },
    {
        "epoch": 28,
        "loss": 10.715781211853027,
        "best_loss": 10.715781211853027,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 36.279998779296875,
        "cur_std": 1.3353673934936523,
        "prompt": " Budget 0 Tackle the Basic RCopy)",
        "nll_prompt": -60.6640625
    },
    {
        "epoch": 29,
        "loss": 10.760313034057617,
        "best_loss": 10.715781211853027,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 39.93437576293945,
        "cur_std": 1.2522617340087892,
        "prompt": " Budget 0 Tackle the Basic RCopy You",
        "nll_prompt": -61.71875
    },
    {
        "epoch": 30,
        "loss": 10.906719207763672,
        "best_loss": 10.715781211853027,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 38.7599983215332,
        "cur_std": 1.289365863800049,
        "prompt": " Budget 0 Tackle the Basic RCopyd",
        "nll_prompt": -63.1640625
    },
    {
        "epoch": 31,
        "loss": 10.82406234741211,
        "best_loss": 10.715781211853027,
        "best_kl": 34.037498474121094,
        "best_std": 1.3147479057312013,
        "cur_kl": 34.877498626708984,
        "cur_std": 1.271653652191162,
        "prompt": " Budget 0 Tackle the meat RCopyd",
        "nll_prompt": -64.296875
    },
    {
        "epoch": 32,
        "loss": 10.690000534057617,
        "best_loss": 10.690000534057617,
        "best_kl": 32.12687301635742,
        "best_std": 1.2237192153930665,
        "cur_kl": 32.12687301635742,
        "cur_std": 1.2237192153930665,
        "prompt": " Budget 0 Tackle the meat RCopy]",
        "nll_prompt": -64.140625
    },
    {
        "epoch": 33,
        "loss": 11.065155982971191,
        "best_loss": 10.690000534057617,
        "best_kl": 30.735624313354492,
        "best_std": 1.2010361671447753,
        "cur_kl": 30.735624313354492,
        "cur_std": 1.2010361671447753,
        "prompt": " Budget 0 Tackle the meat RArguments]",
        "nll_prompt": -69.2578125
    },
    {
        "epoch": 34,
        "loss": 11.336874961853027,
        "best_loss": 10.690000534057617,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 29.96500015258789,
        "cur_std": 1.1985531806945802,
        "prompt": " Budget 0 Tackle the meat MArguments]",
        "nll_prompt": -69.453125
    },
    {
        "epoch": 35,
        "loss": 11.378124237060547,
        "best_loss": 10.690000534057617,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 30.51999855041504,
        "cur_std": 1.212468719482422,
        "prompt": " 2 0 Tackle the meat MArguments]",
        "nll_prompt": -68.359375
    },
    {
        "epoch": 36,
        "loss": 10.985937118530273,
        "best_loss": 10.690000534057617,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 30.43062400817871,
        "cur_std": 1.224900722503662,
        "prompt": " 2 0 Tackle the meat Mingu]",
        "nll_prompt": -64.921875
    },
    {
        "epoch": 37,
        "loss": 10.188593864440918,
        "best_loss": 10.188593864440918,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 30.354999542236328,
        "cur_std": 1.2153615951538086,
        "prompt": " 2 0 Tackle the meat Mm]",
        "nll_prompt": -58.6328125
    },
    {
        "epoch": 38,
        "loss": 9.914688110351562,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 30.89812469482422,
        "cur_std": 1.2465367317199707,
        "prompt": " 2 0 Tackle the meat Mm.",
        "nll_prompt": -55.46875
    },
    {
        "epoch": 39,
        "loss": 10.280312538146973,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 31.38249969482422,
        "cur_std": 1.2560648918151855,
        "prompt": "turned 0 Tackle the meat Mm.",
        "nll_prompt": -59.296875
    },
    {
        "epoch": 40,
        "loss": 10.748281478881836,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 31.244375228881836,
        "cur_std": 1.258688259124756,
        "prompt": "ICs 0 Tackle the meat Mm.",
        "nll_prompt": -62.3046875
    },
    {
        "epoch": 41,
        "loss": 10.675312042236328,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 33.8068733215332,
        "cur_std": 1.2843003273010254,
        "prompt": "ICs 0 Tackle the Monroe Mm.",
        "nll_prompt": -66.3671875
    },
    {
        "epoch": 42,
        "loss": 11.044687271118164,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 32.859375,
        "cur_std": 1.2680612564086915,
        "prompt": "Lost 0 Tackle the Monroe Mm.",
        "nll_prompt": -65.703125
    },
    {
        "epoch": 43,
        "loss": 10.931875228881836,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 33.0881233215332,
        "cur_std": 1.2666723251342773,
        "prompt": " EVEN 0 Tackle the Monroe Mm.",
        "nll_prompt": -63.828125
    },
    {
        "epoch": 44,
        "loss": 10.995311737060547,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 33.45249938964844,
        "cur_std": 1.2763859748840332,
        "prompt": " EVEN 0 Tackle themL Mm.",
        "nll_prompt": -65.0
    },
    {
        "epoch": 45,
        "loss": 10.840312957763672,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 33.760623931884766,
        "cur_std": 1.2949097633361817,
        "prompt": " EVEN 0 Tackle the= Mm.",
        "nll_prompt": -63.59375
    },
    {
        "epoch": 46,
        "loss": 10.872187614440918,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 32.69187545776367,
        "cur_std": 1.246181106567383,
        "prompt": "------------------------- 0 Tackle the= Mm.",
        "nll_prompt": -64.921875
    },
    {
        "epoch": 47,
        "loss": 10.612499237060547,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 31.755624771118164,
        "cur_std": 1.268474006652832,
        "prompt": "master 0 Tackle the= Mm.",
        "nll_prompt": -63.671875
    },
    {
        "epoch": 48,
        "loss": 10.785469055175781,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 31.321874618530273,
        "cur_std": 1.2760369300842285,
        "prompt": "master 3 Tackle the= Mm.",
        "nll_prompt": -64.2578125
    },
    {
        "epoch": 49,
        "loss": 11.03531265258789,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 30.743749618530273,
        "cur_std": 1.2638371467590332,
        "prompt": "master 3 Tackle the all Mm.",
        "nll_prompt": -64.6875
    },
    {
        "epoch": 50,
        "loss": 11.260313034057617,
        "best_loss": 9.914688110351562,
        "best_kl": 29.96500015258789,
        "best_std": 1.1985531806945802,
        "cur_kl": 31.21562385559082,
        "cur_std": 1.261540985107422,
        "prompt": "master 158 Tackle the all Mm.",
        "nll_prompt": -69.375
    }
]